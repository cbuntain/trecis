{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_title = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = pd.read_csv(\"trec2019_test_results_run_%s.csv\" % run_title, dtype={\n",
    "    \"tweet_id\": np.int64,\n",
    "})\n",
    "priority_df = pd.read_csv(\"trec2019_test_results_priority_run_%s.csv\" % run_title, dtype={\n",
    "    \"tweet_id\": np.int64,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num_to_id_map = {}\n",
    "\n",
    "with open(\"TRECIS-2019-A-Test.topics\", \"r\") as in_file:\n",
    "    topic_num = \"\"\n",
    "    topic_id = \"\"\n",
    "    \n",
    "    for line in in_file:\n",
    "        \n",
    "        if line.strip() == \"</top>\":\n",
    "            topic_num_to_id_map[topic_id] = topic_num\n",
    "        \n",
    "        if line.startswith(\"<num>\"):\n",
    "            topic_num = line.partition(\">\")[-1].partition(\"<\")[0]\n",
    "              \n",
    "        if line.startswith(\"<dataset>\"):\n",
    "            topic_id = line.partition(\">\")[-1].partition(\"<\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'floodChoco2019': 'TRECIS-CTIT-H-Test-022',\n",
       " 'fireAndover2019': 'TRECIS-CTIT-H-Test-023',\n",
       " 'earthquakeCalifornia2014': 'TRECIS-CTIT-H-Test-024',\n",
       " 'earthquakeBohol2013': 'TRECIS-CTIT-H-Test-025',\n",
       " 'hurricaneFlorence2018': 'TRECIS-CTIT-H-Test-026',\n",
       " 'shootingDallas2017': 'TRECIS-CTIT-H-Test-027',\n",
       " 'fireYMM2016': 'TRECIS-CTIT-H-Test-028'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_num_to_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/2019/trecis2019-A-test.hurricaneFlorence2018.json.gz\n",
      "../data/2019/trecis2019-A-test.fireYMM2016.json.gz\n",
      "../data/2019/trecis2019-A-test.shootingDallas2017.json.gz\n",
      "../data/2019/trecis2019-A-test.floodChoco2019.json.gz\n",
      "../data/2019/trecis2019-A-test.earthquakeBohol2013.json.gz\n",
      "../data/2019/trecis2019-A-test.earthquakeCalifornia2014.json.gz\n",
      "../data/2019/trecis2019-A-test.fireAndover2019.json.gz\n",
      "Found\n",
      "1100409564803956744 1100409564803956744 False\n"
     ]
    }
   ],
   "source": [
    "tweet_id_to_topic_map = {}\n",
    "tweet_id_to_count_map = {}\n",
    "\n",
    "for file_path in glob.iglob(\"../data/2019/*2019*test*.json.gz\"):\n",
    "    print(file_path)\n",
    "    counter = 1\n",
    "    with gzip.open(file_path, \"rb\") as in_file:\n",
    "        for line_ in in_file:\n",
    "            line = line_.decode(\"utf8\")\n",
    "            tweet_entry = json.loads(line)\n",
    "            \n",
    "            tweet_id = np.int64(tweet_entry[\"allProperties\"][\"id\"])\n",
    "            tweet_topic = tweet_entry[\"topic\"]\n",
    "            \n",
    "            if ( '1100409564803956744' == tweet_entry[\"allProperties\"][\"id\"] ):\n",
    "                print(\"Found\")\n",
    "                print(tweet_entry[\"allProperties\"][\"id\"], tweet_id, tweet_entry[\"allProperties\"][\"id\"] == tweet_id)\n",
    "            \n",
    "            tweet_id_to_topic_map[tweet_id] = topic_num_to_id_map[tweet_topic]\n",
    "            tweet_id_to_count_map[tweet_id] = counter\n",
    "            \n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9308, 9503)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_id_to_count_map), priority_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {row[\"tweet_id\"]: row[\"label\"] for idx, row in category_df.iterrows()}\n",
    "priority_map = {row[\"tweet_id\"]: row[\"priority\"] for idx, row in priority_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df[\"inc_id\"] = category_df[\"tweet_id\"].apply(tweet_id_to_topic_map.get)\n",
    "category_df[\"count\"] = category_df[\"tweet_id\"].apply(tweet_id_to_count_map.get)\n",
    "category_df[\"priority\"] = category_df[\"tweet_id\"].apply(priority_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_scorer = {\n",
    "    1 : 0.75,\n",
    "    0 : 0.25\n",
    "}\n",
    "\n",
    "with open(\"nyu-smapp_run_%s.csv\" % run_title, \"w\") as out_file:\n",
    "    for row in category_df.drop_duplicates(subset=\"tweet_id\").itertuples():\n",
    "        content = [\n",
    "            row.inc_id, \n",
    "            \"Q0\", \n",
    "            row.tweet_id,\n",
    "            row.count,\n",
    "            priority_scorer[row.priority],\n",
    "            str([row.label]).replace(\"'\", '\"'),\n",
    "            \"nyu-smapp_%s\" % run_title\n",
    "        ]\n",
    "        out_file.write(\"\\t\".join([str(x) for x in content]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
